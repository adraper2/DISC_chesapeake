raw_text
clear
quit
clean
raw_text <- url %>% read_html() %>% html_text()
raw_text
raw_text <- url %>% read_html()
raw_text
reviews <- url %>% html_nodes( ".reviewBodyCell")
reviews <- webpage %>% html_nodes( ".reviewBodyCell")
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell")
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
reviews
review_tags <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_name()
review_tags
reviews <- webpage %>% html_nodes( ".mainText") %>% html_text()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
reviews2 <- webpage %>% html_nodes( ".mainText") %>% html_text()
reviews2
reviews2 <- webpage %>% html_nodes( ".tightVert , .padTopMd , .mainText") %>% html_text()
reviews2
reviews2 <- webpage %>% html_nodes( ".reviewBodyCell , .mainText") %>% html_text()
reviews2 <- webpage %>% html_nodes( ".mainText") %>% html_text()
reviews
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
reviews
regexpr('Share on Facebook', reviews[1])
regexpr('Share on Facebook', reviews[1])[1]
substr(x=reviews[1],stop = regexpr('Share on Facebook', reviews[1])[1])
substr(x=reviews[1],start=1, stop = regexpr('Share on Facebook', reviews[1])[1])
substr(x=reviews[1],start=1, stop = regexpr('Share on Facebook', reviews[1])[1]-1)
length(reviews)
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
if (page_num <= 1){
for(x in 1:length(reviews)){
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[1])[1]-1)
paste(current)
}
}
}
getReviews
getReviews
getReviews()
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
if (page_num <= 1){
for(x in 1:length(reviews)){
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[1])[1]-1)
print(paste(current))
}
}
}
getReviews()
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
if (page_num <= 1){
for(x in 1:length(reviews)){
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
print(paste(current))
}
}
}
getReviews()
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
if (page_num <= 1){
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
print(paste(current))
}
}
}
getReviews()
library(googlesheets)
gs_auth(new_user = TRUE)
gs_read()
gs_title("r_scraping")
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
counter <- 1
if (page_num <= 1){
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
gs_add_row("1t1W_TKnV5Ouw5GZDHsbyv_MD2WnSHCd2GEHHk9D6l", ws = counter, input = current, verbose = FALSE)
counter <- counter + 1
print(paste(current))
}
}
}
getReviews()
review_data <- getReviews()
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
review_data <- vector(mode = "character", length = length(reviews))
if (page_num <= 1){
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[x] <- current
print(paste(current))
}
return(review_data)
}
}
review_data <- getReviews()
review_data
write.csv(review_data, file = "Veolia.csv")
con<-file('Veolia.csv',encoding="UTF-8")
write.csv(review_data, file = con)
con<-file('Veolia.csv',encoding="UTF-16")
write.csv(review_data, file = con)
url[1:length(url)-4]
url[1:(length(url)-4)]
length(url)
url
url[1][1:(length(url)-4)]
url[1]
url[1,1:(length(url)-4)]
url <- url[1]
url[1:(length(url)-4)]
substr(x=url,start=1,stop=(length(url)-4))
substr(x=url,start=1,stop=(length(url[1])-4))
substr(x=url,start=1,stop=(nchar(url)-4))
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
if (page_num <= 1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
review_data <- vector(mode = "character", length = length(reviews))
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[x] <- current
print(paste(current))
}
return(review_data)
} else {
url_list <- vector(mode = "character", length = page_num)
for (i in 1:page_num){
url_list[i] <- paste(substr(x=url,start=1,stop=(nchar(url)-4)), "P",as.character(i),".htm")
}
return(url_list)
}
}
review_data <- getReviews(page_num = 5)
review_data
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
if (page_num <= 1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
review_data <- vector(mode = "character", length = length(reviews))
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[x] <- current
print(paste(current))
}
return(review_data)
} else {
url_list <- vector(mode = "character", length = page_num)
for (i in 1:page_num){
url_list[i] <- paste(substr(x=url,start=1,stop=(nchar(url)-4)), "_P",as.character(i),".htm", sep="")
}
return(url_list)
}
}
review_data <- getReviews(page_num = 5)
review_data
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
if (page_num <= 1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
review_data <- vector(mode = "character", length = length(reviews))
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[x] <- current
print(paste(current))
}
return(review_data)
} else {
url_list <- vector(mode = "character", length = page_num)
for (i in 1:page_num){
if(i>1){
url_list[i] <- paste(substr(x=url,start=1,stop=(nchar(url)-4)), "_P",as.character(i),".htm", sep="")
} else{
url_list[i] <- url
}
}
return(url_list)
}
}
review_data <- getReviews(page_num = 5)
review_data
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
if (page_num <= 1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
review_data <- vector(mode = "character", length = length(reviews))
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[x] <- current
print(paste(current))
}
return(review_data)
} else {
url_list <- vector(mode = "character", length = page_num)
for (i in 1:page_num){
if(i>1){
url_list[i] <- paste(substr(x=url,start=1,stop=(nchar(url)-4)), "_P",as.character(i),".htm", sep="")
} else{
url_list[i] <- url
}
}
return(url_list)
}
}
review_data <- getReviews(url="https://www.glassdoor.com/Reviews/U-S-Bank-Reviews-E8937.htm",page_num = 430)
review_data
con<-file('~/Documents/Junior_Year/DataAnalytics/ManhattanUS_bank.csv',encoding="UTF-8")
write.csv(review_data, file = con)
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
if (page_num <= 1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
review_data <- vector(mode = "character", length = length(reviews))
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[x] <- current
print(paste(current))
}
return(review_data)
} else {
url_list <- vector(mode = "character", length = page_num)
for (i in 1:page_num){
if(i>1){
url_list[i] <- paste(substr(x=url,start=1,stop=(nchar(url)-4)), "_P",as.character(i),".htm", sep="")
} else{
url_list[i] <- url
}
}
for (y in 1:page_num){
url <- url_list[y]
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
review_data <- vector(mode = "character", length = page_num*10)
counter <- 1
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[counter] <- current
counter <- counter + 1
print(paste(current))
}
}
return(review_data)
}
}
review_data <- getReviews(url="https://www.glassdoor.com/Reviews/U-S-Bank-Reviews-E8937.htm",page_num = 430)
review_data
con<-file('~/Documents/Junior_Year/DataAnalytics/ManhattanUS_bank.csv',encoding="UTF-8")
write.csv(review_data, file = con)
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
if (page_num <= 1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
review_data <- vector(mode = "character", length = length(reviews))
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[x] <- current
print(paste(current))
}
return(review_data)
} else {
url_list <- vector(mode = "character", length = page_num)
for (i in 1:page_num){
if(i>1){
url_list[i] <- paste(substr(x=url,start=1,stop=(nchar(url)-4)), "_P",as.character(i),".htm", sep="")
} else{
url_list[i] <- url
}
}
for (y in 1:page_num){
url <- url_list[y]
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
review_data <- vector(mode = "character", length = page_num*10)
counter <- 1
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[counter] <- current
counter <- counter + 1
#print(paste(current))
}
}
return(review_data)
}
}
review_data <- getReviews(url="https://www.glassdoor.com/Reviews/U-S-Bank-Reviews-E8937.htm",page_num = 20)
con<-file('~/Documents/Junior_Year/DataAnalytics/Manhattan/US_bank.csv',encoding="UTF-8")
write.csv(review_data, file = con)
library(rvest)
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
if (page_num <= 1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
review_data <- vector(mode = "character", length = length(reviews))
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[x] <- current
print(paste(current))
}
return(review_data)
} else {
url_list <- vector(mode = "character", length = page_num)
for (i in 1:page_num){
if(i>1){
url_list[i] <- paste(substr(x=url,start=1,stop=(nchar(url)-4)), "_P",as.character(i),".htm", sep="")
} else{
url_list[i] <- url
}
}
counter <- 1
for (y in 1:page_num){
url <- url_list[y]
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
review_data <- vector(mode = "character", length = page_num*10)
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[counter] <- current
counter <- counter + 1
#print(paste(current))
}
}
return(review_data)
}
}
review_data <- getReviews(url="https://www.glassdoor.com/Reviews/U-S-Bank-Reviews-E8937.htm",page_num = 20)
con<-file('~/Documents/Junior_Year/DataAnalytics/Manhattan/US_bank.csv',encoding="UTF-8")
write.csv(review_data, file = con)
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
library(rvest)
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
if (page_num <= 1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
review_data <- vector(mode = "character", length = length(reviews))
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[x] <- current
print(paste(current))
}
return(review_data)
} else {
url_list <- vector(mode = "character", length = page_num)
for (i in 1:page_num){
if(i>1){
url_list[i] <- paste(substr(x=url,start=1,stop=(nchar(url)-4)), "_P",as.character(i),".htm", sep="")
} else{
url_list[i] <- url
}
}
counter <- 1
review_data <- vector(mode = "character", length = page_num*10)
for (y in 1:page_num){
url <- url_list[y]
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[counter] <- current
counter <- counter + 1
#print(paste(current))
}
}
return(review_data)
}
}
review_data <- getReviews(url="https://www.glassdoor.com/Reviews/U-S-Bank-Reviews-E8937.htm",page_num = 20)
con<-file('~/Documents/Junior_Year/DataAnalytics/Manhattan/US_bank.csv',encoding="UTF-8")
write.csv(review_data, file = con)
library(rvest)
getReviews <- function(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm", page_num=1){
if (page_num <= 1){
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
review_data <- vector(mode = "character", length = length(reviews))
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[x] <- current
print(paste(current))
}
return(review_data)
} else {
url_list <- vector(mode = "character", length = page_num)
for (i in 1:page_num){
if(i>1){
url_list[i] <- paste(substr(x=url,start=1,stop=(nchar(url)-4)), "_P",as.character(i),".htm", sep="")
} else{
url_list[i] <- url
}
}
counter <- 1
review_data <- vector(mode = "character", length = page_num*10)
for (y in 1:page_num){
url <- url_list[y]
webpage <- url %>% read_html()
reviews <- webpage %>% html_nodes( ".reviewBodyCell") %>% html_text()
for(x in 1:length(reviews)){
reviews <- gsub("Pros", " ", reviews)
reviews <- gsub("Cons", " ", reviews)
reviews <- gsub("Advice to Management", " ", reviews)
current <- substr(x=reviews[x],start=1, stop = regexpr('Share on Facebook', reviews[x])[1]-1)
review_data[counter] <- current
counter <- counter + 1
#print(paste(current))
}
}
return(review_data)
}
}
review_data <- getReviews(url="https://www.glassdoor.com/Reviews/U-S-Bank-Reviews-E8937.htm",page_num = 430)
con<-file('~/Documents/Junior_Year/DataAnalytics/Manhattan/US_bank.csv',encoding="UTF-8")
write.csv(review_data, file = con)
review_data <- getReviews(url="https://www.glassdoor.com/Reviews/Transdev-Reviews-E413452.htm",page_num = 24)
con<-file('~/Documents/Junior_Year/DataAnalytics/Manhattan/Transdev.csv',encoding="UTF-8")
write.csv(review_data, file = con)
review_data <- getReviews(url="https://www.glassdoor.com/Reviews/First-Student-Reviews-E16694.htm",page_num = 44)
review_data <- getReviews(url="https://www.glassdoor.com/Reviews/First-Student-Reviews-E16694.htm",page_num = 44)
con<-file('~/Documents/Junior_Year/DataAnalytics/Manhattan/First_student.csv',encoding="UTF-8")
write.csv(review_data, file = con)
review_data <- getReviews(url="https://www.glassdoor.com/Reviews/Veolia-Reviews-E20114.htm",page_num = 63)
con<-file('~/Documents/Junior_Year/DataAnalytics/Manhattan/Veolia.csv',encoding="UTF-8")
write.csv(review_data, file = con)
review_data <- getReviews(url="https://www.glassdoor.com/Reviews/Harvard-Pilgrim-Reviews-E2816.htm",page_num = 10)
con<-file('~/Documents/Junior_Year/DataAnalytics/Manhattan/Harvard_pilgrim.csv',encoding="UTF-8")
write.csv(review_data, file = con)
review_data <- getReviews(url="https://www.glassdoor.com/Reviews/TD-Reviews-E3767.htm",page_num = 144)
con<-file('~/Documents/Junior_Year/DataAnalytics/Manhattan/TD_bank.csv',encoding="UTF-8")
write.csv(review_data, file = con)
review_data <- getReviews(url="https://www.glassdoor.com/Reviews/Motorola-Solutions-Reviews-E427189.htm",page_num = 68)
con<-file('~/Documents/Junior_Year/DataAnalytics/Manhattan/Motorola.csv',encoding="UTF-8")
write.csv(review_data, file = con)
install.packages("gjam")
library(gjam)
install.packages("gjam")
install.packages("RcppArmadillo")
install.packages(gjam)
install.packages("gjam")
install.packages("RcppArmadillo")
install.packages("gjam")
library(gjam)
install.packages("coda")
install.packages("gridExtra")
install.packages('mgcv')
install.packages('zoo')
install.packages('Matrix')
install.packages('cowplot')
install.packages('spBayes')
install.packages('snow')
install.packages('snowfall')
install.packages('rlecuyer')
range(3,1)
diff(3,1)
25-21-1
25-21+1
l <- vector("list", 3)
l[[1]] <- 7
load('training_set.rda')
setwd("~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/Landsat8/")
load('training_set.rda')
setwd("~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/Landsat8/")
load(file='training_set.rda')
setwd("~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/")
load(file='training_set.rda')
View(training)
