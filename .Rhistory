theme_classic() + theme(legend.position="none") +
scale_x_discrete(labels = c('1'= 'Mean', '2'='Bilateral', '3'='Nonlocal', '5'='Adobe 50%', '6'='Adobe 100%'))+
scale_y_continuous(breaks=0:10)
ggplot(data=results.df, aes(x=score)) +
geom_histogram(binwidth = 1, color="black", fill="cyan3") +
labs(title="Distributions of Image Quality Scores",x="Quality Score", y = "Frequency") +
scale_x_continuous(breaks=0:10) +
theme_classic()
freqs <- tabulate(results.df$score)
ggplot(data=results.df, aes(x=score, color=img_num)) +
geom_point(shape=4, size=5, stat = "count") +
labs(title="Filter Method Scores and their Frequencies",x="Quality Score", y = "Frequency",  color = "Filter Method") +
scale_y_continuous(breaks=0:10) +
scale_x_continuous(breaks=0:10) +
scale_color_manual(labels = c('1'= 'Mean', '2'='Bilateral', '3'='Nonlocal', '5'='Adobe 50%', '6'='Adobe 100%'), values = c('#F8766D', '#F8766D','#7CAE00','#00BFC4','#C77CFF'))+
theme_classic() + theme(legend.position = "bottom")
summary(results.df)
table(results.df)
library(googlesheets)
library(ggplot2)
results.df <- gs_read(gs_key("1ZJiwEa-tObwH0zTmWqEqwqxihwS1X0BncxzBgG75TCI"))
results.df <- results.df[-(1:4),] # trim the test rows
results.df <- results.df[-35,]
results.df$img_num <- as.factor(results.df$img_num)
summary(
aov(score ~ img_num, data=results.df)
)
boxplot(score ~ img_num,
data = results.df,
col= c("blue", "yellow","green", "pink", "red"),
xlab="Filter Method",
ylab="Quality Score from Participant",
main="Quality Scores of Filtering Methods")
# ADD Correlation and reorder boxplot by PSNR
ggplot(data=results.df, aes(x=img_num, y =score, fill=img_num)) + geom_boxplot() +
stat_summary(fun.y=mean, geom="point", shape=23, size=4) +
labs(title="Distributions of Image Quality Scores by Filter Method",x="Filter Method", y = "Quality Score") +
theme_classic() + theme(legend.position="none") +
scale_x_discrete(labels = c('1'= 'Mean', '2'='Bilateral', '3'='Nonlocal', '5'='Adobe 50%', '6'='Adobe 100%'))+
scale_y_continuous(breaks=0:10)
ggplot(data=results.df, aes(x=score)) +
geom_histogram(binwidth = 1, color="black", fill="cyan3") +
labs(title="Distributions of Image Quality Scores",x="Quality Score", y = "Frequency") +
scale_x_continuous(breaks=0:10) +
theme_classic()
freqs <- tabulate(results.df$score)
ggplot(data=results.df, aes(x=score, color=img_num)) +
geom_point(shape=4, size=5, stat = "count") +
labs(title="Filter Method Scores and their Frequencies",x="Quality Score", y = "Frequency",  color = "Filter Method") +
scale_y_continuous(breaks=0:10) +
scale_x_continuous(breaks=0:10) +
scale_color_manual(labels = c('1'= 'Mean', '2'='Bilateral', '3'='Nonlocal', '5'='Adobe 50%', '6'='Adobe 100%'), values = c('#FCE300', '#F8766D','#7CAE00','#00BFC4','#C77CFF'))+
theme_classic() + theme(legend.position = "bottom")
summary(results.df)
table(results.df)
results.df <- results.df[-(1:4),] # trim the test rows
results.df <- results.df[-35,]
results.df$img_num <- as.factor(results.df$img_num)
summary(
aov(score ~ img_num, data=results.df)
)
library(googlesheets)
library(ggplot2)
results.df <- gs_read(gs_key("1ZJiwEa-tObwH0zTmWqEqwqxihwS1X0BncxzBgG75TCI"))
results.df <- results.df[-(1:4),] # trim the test rows
results.df <- results.df[-35,]
results.df$img_num <- as.factor(results.df$img_num)
summary(
aov(score ~ img_num, data=results.df)
)
View(results.df)
cbind(rep(sample(1:3,1),3),sample(1:3, replace = FALSE), sample(1:3, replace = FALSE))
library(googlesheets)
library(ggplot2)
results.df <- gs_read(gs_key("1ZJiwEa-tObwH0zTmWqEqwqxihwS1X0BncxzBgG75TCI"))
results.df <- results.df[-(1:4),] # trim the test rows
results.df <- results.df[-35,]
results.df$img_num <- as.factor(results.df$img_num)
summary(
aov(score ~ img_num, data=results.df)
)
boxplot(score ~ img_num,
data = results.df,
col= c("blue", "yellow","green", "pink", "red"),
xlab="Filter Method",
ylab="Quality Score from Participant",
main="Quality Scores of Filtering Methods")
# ADD Correlation and reorder boxplot by PSNR
ggplot(data=results.df, aes(x=img_num, y =score, fill=img_num)) + geom_boxplot() +
stat_summary(fun.y=mean, geom="point", shape=23, size=4) +
labs(title="Distributions of Image Quality Scores by Filter Method",x="Filter Method", y = "Quality Score") +
theme_classic() + theme(legend.position="none") +
scale_x_discrete(labels = c('1'= 'Mean', '2'='Bilateral', '3'='Nonlocal', '5'='Adobe 50%', '6'='Adobe 100%'))+
scale_y_continuous(breaks=0:10)
ggplot(data=results.df, aes(x=score)) +
geom_histogram(binwidth = 1, color="black", fill="cyan3") +
labs(title="Distributions of Image Quality Scores",x="Quality Score", y = "Frequency") +
scale_x_continuous(breaks=0:10) +
theme_classic()
freqs <- tabulate(results.df$score)
ggplot(data=results.df, aes(x=score, color=img_num)) +
geom_point(shape=4, size=5, stat = "count") +
labs(title="Filter Method Scores and their Frequencies",x="Quality Score", y = "Frequency",  color = "Filter Method") +
scale_y_continuous(breaks=0:10) +
scale_x_continuous(breaks=0:10) +
scale_color_manual(labels = c('1'= 'Mean', '2'='Bilateral', '3'='Nonlocal', '5'='Adobe 50%', '6'='Adobe 100%'), values = c('#FCE300', '#F8766D','#7CAE00','#00BFC4','#C77CFF'))+
theme_classic() + theme(legend.position = "bottom")
summary(results.df)
table(results.df)
View(results.df)
summary(
aov(log(score) ~ img_num, data=results.df)
)
summary(
aov(log(score+1) ~ img_num, data=results.df)
)
results.df$log_score <- as.factor(log(score+1))
results.df$log_score <- as.factor(log(results.df$score+1))
results.df$log_score <- log(results.df$score+1)
ggplot(data=results.df, aes(x=img_num, y =log_score, fill=img_num)) + geom_boxplot() +
stat_summary(fun.y=mean, geom="point", shape=23, size=4) +
labs(title="Distributions of Image Quality Scores by Filter Method",x="Filter Method", y = "Quality Score") +
theme_classic() + theme(legend.position="none") +
scale_x_discrete(labels = c('1'= 'Mean', '2'='Bilateral', '3'='Nonlocal', '5'='Adobe 50%', '6'='Adobe 100%'))+
scale_y_continuous(breaks=0:10)
aggregate(log_score~img_num,data=results.df,FUN=var)
results.df$log_score <- sqrt(results.df$score+1)
aggregate(log_score~img_num,data=results.df,FUN=var)
survey.df <- data.frame(gs_read(gs_key("1H-nJggWpOutHZG8YScab5UgrWqlnNDvaMWTDdtCytDA")))
library(googlesheets)
survey.df <- data.frame(gs_read(gs_key("1H-nJggWpOutHZG8YScab5UgrWqlnNDvaMWTDdtCytDA")))
aggregate(depressed~island,data=results.df,FUN=var)
aggregate(depressed~island,data=survey.df,FUN=var)
aggregate(depressed~island,data=survey.df,FUN=mean)
aggregate(energetic~island,data=survey.df,FUN=mean)
aggregate(energetic~island,data=survey.df,FUN=var)
aggregate(tired~island,data=survey.df,FUN=mean)
aggregate(tired~island,data=survey.df,FUN=var)
hist(depressed)
hist(survey.df$depressed)
hist(log(survey.df$depressed))
hist(survey.df$depressed)
d.means <- aggregate(depressed~island,data=survey.df,FUN=mean)
d.vars <- aggregate(depressed~island,data=survey.df,FUN=var)
d.means + (2*sqrt(d.vars))
d.means[,2] + (2*sqrt(d.vars[,2]))
sum(pops)
pops <- c(8730,11386,14668)
sum(pops)
samples/pops
samples <- c(14,20,27)
samples/pops
error <- (2*sum(sqrt(pops/sum(pops)) * (d.vars[,2]/samples) * (1-(samples/pops))))
error
cat(.means[,2] - error, d.means[,2] + error)
cat(d.means[,2] - error, d.means[,2] + error)
cat(mean(survey.dfdepressed) - error, d.means[,2] + error)
cat(mean(survey.df$depressed) - error, d.means[,2] + error)
# gets means and variances (CHANGE TO YOUR VARIABLE OF INTEREST)
my.mean <- mean(survey.df$depressed)
cat(my.mean - error, my.mean + error)
mean(survey.df$depressed)
# gets means and variances (CHANGE TO YOUR VARIABLE OF INTEREST)
my.mean <- mean(na.omit(survey.df$depressed))
na.omit(survey.df)
survey.df <- na.omit(survey.df)
survey.df <- data.frame(gs_read(gs_key("1H-nJggWpOutHZG8YScab5UgrWqlnNDvaMWTDdtCytDA")))
survey.df <- na.omit(survey.df)
View(survey.df)
survey.df <- data.frame(gs_read(gs_key("1H-nJggWpOutHZG8YScab5UgrWqlnNDvaMWTDdtCytDA")))
View(survey.df)
survey.df <- na.omit(survey.df)
survey.df <- data.frame(gs_read(gs_key("1H-nJggWpOutHZG8YScab5UgrWqlnNDvaMWTDdtCytDA")))
View(survey.df)
survey.df <- data.frame(gs_read(gs_key("1H-nJggWpOutHZG8YScab5UgrWqlnNDvaMWTDdtCytDA")))
View(survey.df)
survey.df <- na.omit(survey.df)
View(survey.df)
# gets means and variances (CHANGE TO YOUR VARIABLE OF INTEREST)
my.mean <- mean(na.omit(survey.df$depressed))
d.means <- aggregate(depressed~island,data=survey.df,FUN=mean)
d.vars <- aggregate(depressed~island,data=survey.df,FUN=var)
error <- (2*sum(sqrt(pops/sum(pops)) * (d.vars[,2]/samples) * (1-(samples/pops))))
cat(my.mean - error, my.mean + error)
# gets means and variances (CHANGE TO YOUR VARIABLE OF INTEREST)
my.mean.d <- mean(na.omit(survey.df$depressed))
d.means <- aggregate(depressed~island,data=survey.df,FUN=mean)
d.vars <- aggregate(depressed~island,data=survey.df,FUN=var)
error <- (2*sum(sqrt(pops/sum(pops)) * (d.vars[,2]/samples) * (1-(samples/pops))))
cat(my.mean.d - error, my.mean.d + error)
# gets means and variances (CHANGE TO YOUR VARIABLE OF INTEREST)
my.mean.d <- mean(survey.df$depressed)
# energetic
my.mean.e <- mean(survey.df$energetic)
# tired
my.mean.t <- mean(survey.df$tired)
t.means <- aggregate(tired~island,data=survey.df,FUN=mean)
t.vars <- aggregate(tired~island,data=survey.df,FUN=var)
# energetic
my.mean.e <- mean(survey.df$energetic)
e.means <- aggregate(energetic~island,data=survey.df,FUN=mean)
e.vars <- aggregate(energetic~island,data=survey.df,FUN=var)
error <- (2*sum(sqrt(pops/sum(pops)) * (e.vars[,2]/samples) * (1-(samples/pops))))
cat(my.mean.d - error, my.mean.d + error)
error <- (2*sum(sqrt(pops/sum(pops)) * (t.vars[,2]/samples) * (1-(samples/pops))))
cat(my.mean.d - error, my.mean.d + error)
# energetic
my.mean.e <- mean(survey.df$energetic)
e.means <- aggregate(energetic~island,data=survey.df,FUN=mean)
e.vars <- aggregate(energetic~island,data=survey.df,FUN=var)
error <- (2*sum(sqrt(pops/sum(pops)) * (e.vars[,2]/samples) * (1-(samples/pops))))
cat(my.mean.d - error, my.mean.d + error)
# tired
my.mean.t <- mean(survey.df$tired)
t.means <- aggregate(tired~island,data=survey.df,FUN=mean)
t.vars <- aggregate(tired~island,data=survey.df,FUN=var)
error.t <- (2*sum(sqrt(pops/sum(pops)) * (t.vars[,2]/samples) * (1-(samples/pops))))
cat(my.mean.d - error.t, my.mean.d + error.t)
# energetic
my.mean.e <- mean(survey.df$energetic)
e.means <- aggregate(energetic~island,data=survey.df,FUN=mean)
e.vars <- aggregate(energetic~island,data=survey.df,FUN=var)
error.e <- (2*sum(sqrt(pops/sum(pops)) * (e.vars[,2]/samples) * (1-(samples/pops))))
cat(my.mean.e - error.e, my.mean.e + error.e)
my.mean.t <- mean(survey.df$tired)
t.means <- aggregate(tired~island,data=survey.df,FUN=mean)
t.vars <- aggregate(tired~island,data=survey.df,FUN=var)
error.t <- (2*sum(sqrt(pops/sum(pops)) * (t.vars[,2]/samples) * (1-(samples/pops))))
cat(my.mean.t - error.t, my.mean.t + error.t)
error.d <- (2*sum(sqrt(pops/sum(pops)) * (d.vars[,2]/samples)))
cat(my.mean.d - error.d, my.mean.d + error.d)
error.e <- (2*sum(sqrt(pops/sum(pops)) * (e.vars[,2]/samples) ))
cat(my.mean.e - error.e, my.mean.e + error.e)
error.t <- (2*sum(sqrt(pops/sum(pops)) * (t.vars[,2]/samples)))
hist(survey.df$energetic)
hist(survey.df$tired)
hist(survey.df$depressed, main="Distribution of Pop. Depressed Scores", xlab = "Depressed Score")
hist(survey.df$depressed, main="Distribution of Pop. Depressed Scores", xlab = "Depressed Score")
hist(survey.df$energetic, main="Distribution of Pop. Energetic Scores", xlab = "Energetic Score")
hist(survey.df$tired, main="Distribution of Pop. Tired Scores", xlab = "Tired Score")
hist(survey.df$depressed, main="Distribution of Sample Depressed Scores", xlab = "Depressed Score")
hist(survey.df$energetic, main="Distribution of Sample Energetic Scores", xlab = "Energetic Score")
hist(survey.df$tired, main="Distribution of Sample Tired Scores", xlab = "Tired Score")
# gets means and variances (CHANGE TO YOUR VARIABLE OF INTEREST)
my.mean.d <- aggregate(depressed~island,data=survey.df,FUN=mean)[1,1]
# gets means and variances (CHANGE TO YOUR VARIABLE OF INTEREST)
my.mean.d <- aggregate(depressed~island,data=survey.df,FUN=mean)[3,1]
# gets means and variances (CHANGE TO YOUR VARIABLE OF INTEREST)
my.mean.d <- aggregate(depressed~island,data=survey.df,FUN=mean)[1,2]
# gets means and variances (CHANGE TO YOUR VARIABLE OF INTEREST)
my.mean.d <- aggregate(depressed~island,data=survey.df,FUN=mean)[1,2] + aggregate(depressed~island,data=survey.df,FUN=mean)[2,2]
aggregate(depressed~island,data=survey.df,FUN=mean)[2,2]
ggregate(depressed~island,data=survey.df,FUN=mean)[1,2]
aggregate(depressed~island,data=survey.df,FUN=mean)[1,2]
aggregate(depressed~island,data=survey.df,FUN=mean)[2,3]
aggregate(depressed~island,data=survey.df,FUN=mean)[3,2]
aggregate(depressed~island,data=survey.df,FUN=mean)[2,2]
my.mean.d <- aggregate(depressed~island,data=survey.df,FUN=mean)[1,2]*(pops[1]/sum(pops)) +
aggregate(depressed~island,data=survey.df,FUN=mean)[2,2]*(pops[2]/sum(pops)) +
aggregate(depressed~island,data=survey.df,FUN=mean)[3,2]*(pops[3]/sum(pops))
d.means <- aggregate(depressed~island,data=survey.df,FUN=mean)
d.vars <- aggregate(depressed~island,data=survey.df,FUN=var)
error.d <- (2*sum(sqrt(pops/sum(pops)) * (d.vars[,2]/samples)))
cat(my.mean.d - error.d, my.mean.d + error.d)
# energetic
my.mean.e <- aggregate(energetic~island,data=survey.df,FUN=mean)[1,2]*(pops[1]/sum(pops)) +
aggregate(energetic~island,data=survey.df,FUN=mean)[2,2]*(pops[2]/sum(pops)) +
aggregate(energetic~island,data=survey.df,FUN=mean)[3,2]*(pops[3]/sum(pops))
e.means <- aggregate(energetic~island,data=survey.df,FUN=mean)
e.vars <- aggregate(energetic~island,data=survey.df,FUN=var)
error.e <- (2*sum(sqrt(pops/sum(pops)) * (e.vars[,2]/samples) ))
cat(my.mean.e - error.e, my.mean.e + error.e)
# tired
my.mean.t <- aggregate(tired~island,data=survey.df,FUN=mean)[1,2]*(pops[1]/sum(pops)) +
aggregate(tired~island,data=survey.df,FUN=mean)[2,2]*(pops[2]/sum(pops)) +
aggregate(tired~island,data=survey.df,FUN=mean)[3,2]*(pops[3]/sum(pops))
t.means <- aggregate(tired~island,data=survey.df,FUN=mean)
t.vars <- aggregate(tired~island,data=survey.df,FUN=var)
error.t <- (2*sum(sqrt(pops/sum(pops)) * (t.vars[,2]/samples)))
cat(my.mean.t - error.t, my.mean.t + error.t)
my.mean.d
my.mean.e
my.mean.t
error.d <- (2*sum(sqrt(pops/sum(pops))^2 * (d.vars[,2]/samples)))
cat(my.mean.d - error.d, my.mean.d + error.d)
error.e <- (2*sum(sqrt(pops/sum(pops))^2 * (e.vars[,2]/samples) ))
cat(my.mean.e - error.e, my.mean.e + error.e)
error.t <- (2*sum(sqrt(pops/sum(pops))^2 * (t.vars[,2]/samples)))
cat(my.mean.t - error.t, my.mean.t + error.t)
summary(
aov(depressed ~ island, data=survey.df)
)
summary(
aov(energetic ~ island, data=survey.df)
)
summary(
aov(tired ~ island, data=survey.df)
)
t.vars
d.vars
e.vars
#boxplots
ggplot(data=survey.df, aes(x=island, y =depression, fill=img_num)) + geom_boxplot() +
stat_summary(fun.y=mean, geom="point", shape=23, size=4) +
labs(title="Distributions of Depression Score between Islands",x="Island", y = "Depression Score") +
theme_classic() + theme(legend.position="none") +
scale_y_continuous(breaks=0:10)
library(ggplot2)
#boxplots
ggplot(data=survey.df, aes(x=island, y =depression, fill=img_num)) + geom_boxplot() +
stat_summary(fun.y=mean, geom="point", shape=23, size=4) +
labs(title="Distributions of Depression Score between Islands",x="Island", y = "Depression Score") +
theme_classic() + theme(legend.position="none") +
scale_y_continuous(breaks=0:10)
#boxplots
ggplot(data=survey.df, aes(x=island, y =depression, fill=island)) + geom_boxplot() +
stat_summary(fun.y=mean, geom="point", shape=23, size=4) +
labs(title="Distributions of Depression Score between Islands",x="Island", y = "Depression Score") +
theme_classic() + theme(legend.position="none") +
scale_y_continuous(breaks=0:10)
#boxplots
ggplot(data=survey.df, aes(x=island, y =depressed, fill=island)) + geom_boxplot() +
stat_summary(fun.y=mean, geom="point", shape=23, size=4) +
labs(title="Distributions of Depression Score between Islands",x="Island", y = "Depression Score") +
theme_classic() + theme(legend.position="none") +
scale_y_continuous(breaks=0:10)
ggplot(data=survey.df, aes(x=island, y =energetic, fill=island)) + geom_boxplot() +
stat_summary(fun.y=mean, geom="point", shape=23, size=4) +
labs(title="Distributions of Energy Score between Islands",x="Island", y = "Energy Score") +
theme_classic() + theme(legend.position="none") +
scale_y_continuous(breaks=0:10)
ggplot(data=survey.df, aes(x=island, y =tired, fill=island)) + geom_boxplot() +
stat_summary(fun.y=mean, geom="point", shape=23, size=4) +
labs(title="Distributions of Tired Score between Islands",x="Island", y = "Tired Score") +
theme_classic() + theme(legend.position="none") +
scale_y_continuous(breaks=0:10)
shiny::runApp('Documents/Senior_Year/Stats Code/Decomposition_Tables')
runApp('Documents/Senior_Year/Stats Code/Decomposition_Tables')
5%%5
10%%5
0 %% 5
5 %% 5
runApp('Documents/Senior_Year/Stats Code/Decomposition_Tables')
runApp('Documents/Senior_Year/Stats Code/Decomposition_Tables')
runApp('Documents/Senior_Year/Stats Code/Decomposition_Tables')
runApp('Documents/Senior_Year/Stats Code/Decomposition_Tables')
corr?
ds
??corr
??cor
rm(list=ls())
library(raster)
library(magrittr)
library(rgdal)
library(ggplot2)
setwd("~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/")
# create our crop region layer
e <- as(extent(365375, 366400, 4303600, 4304800), 'SpatialPolygons')
crs(e) <- "+proj=utm +zone=18"
# import bands, crop them to the SERC region and raster to a data frame
band2 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B2.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
band3 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B3.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
band4 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B4.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
band5 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B5.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
# covariates for model and dataset construction
evi.value <- 2.5 * ((band5[1,3] - band4[1,3]) / (((band4[1,3] * 6) + band5[1,3]) - ((7.5 * band2[1,3]) + 1)))
ndvi.value <- ((band5[,3] - band4[,3]) / (band5[,3] + band4[,3]))
ndwi.value <- (band3[,3] - band5[,3]) / (band3[,3] + band5[,3])
savi.value <- (1.5 * ((band5[,3] - band4[,3]) / (band5[,3] + band4[,3] + 1.5)))
full.data <- data.frame(x = band2[,1],
y = band2[,2],
band2 = band2[,3],
band3 = band3[,3],
band4 = band4[,3],
band5 = band5[,3],
ndvi = ndvi.value,
evi = evi.value,
ndwi = ndwi.value,
savi = savi.value)
ggplot(data = full.data, aes(x=x, y=y)) + geom_point(aes(color = ndvi))
# Species Map Import
species <- read.csv("~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/DominantSpPerPlot.csv")
# remove plots with no location, if any
species <- species[!is.na(species$easting),]
species <- species[!is.na(species$northing),]
# convert UTM to lat, long
utm.coor.serc <- SpatialPoints(cbind(species$easting,species$northing),
proj4string=CRS("+proj=utm +zone=18"))
# Convert to lat/long
long.lat.coor.serc <- as.data.frame(spTransform(utm.coor.serc,CRS("+proj=longlat")))
species.map <- data.frame(species[2:9],
lat = long.lat.coor.serc$coords.x1,
lon = long.lat.coor.serc$coords.x2,
easting = utm.coor.serc$coords.x1,
northing = utm.coor.serc$coords.x2)
rm(species, long.lat.coor.serc, utm.coor.serc)
training <- data.frame(plot.id = numeric(521), easting = numeric(521), northing = numeric(521),
scam = numeric(521), ivfr = numeric(521), c4 = numeric(521), phau = numeric(521),
spcy = numeric(521), tyla = numeric(521), dead= numeric(521), bare_water = numeric(521),
band2 = numeric(521), band3 = numeric(521), band4 = numeric(521), band5 = numeric(521),
ndvi = numeric(521), evi = numeric(521), ndwi = numeric(521), savi = numeric(521))
count <- 0
for(i in 1:nrow(full.data)){
for (j in 1:nrow(species.map)){
if (species.map[j,11] - full.data[i,1] < 30 & species.map[j,11] - full.data[i,1] > 0 &
species.map[j,12] - full.data[i,2] < 30 & species.map[j,12] - full.data[i,2] > 0){
count = count + 1
training$plot.id[count] <- i
training[count,-c(1)] <- c(full.data[i,1:2],species.map[j,1:8], full.data[i,3:10])
}
}
}
rm(list=ls())
library(ggplot2)
library(randomForest)
library(gridExtra)
library(reprtree)
setwd("~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/")
load(file='training_set.rda')
### PARAMETER VARIABLES
curr.species = 'scam'
train.size = .8
cols.in.training = c(12:16,18:19)
seed.num = 2000
set.seed(seed.num)
current <- training[,which(names(training)==curr.species)]
samp <- sample(nrow(training), train.size * nrow(training))
samp
table(samp)
View(training)
plot.id
training$plot.id
unique(training$plot.id)
nrow(unique(training$plot.id)
)
nrow(unique(training$plot.id))
length(unique(training$plot.id))
set.seed(seed.num)
current <- training[,which(names(training)==curr.species)]
#samp <- sample(nrow(training), train.size * nrow(training))
samp <- sample(training$plot.id, train.size * length(unique(training$plot.id)),replace = FALSE)
# vector of rows to usee
samp.rows <- numeric(length(unique(training$plot.id)))
for (x in 1:length(unique(training$plot.id))){
cat(training[samp[x] %in% training$plot.id])
}
samp.rows <- numeric(length(unique(training$plot.id)))
for (x in 1:length(unique(training$plot.id))){
print(training[samp[x] %in% training$plot.id])
}
samp.rows <- numeric(length(unique(training$plot.id)))
for (x in 1:length(unique(training$plot.id))){
print(samp[x] %in% training$plot.id)
}
samp.rows <- numeric(length(unique(training$plot.id)))
for (x in 1:length(unique(training$plot.id))){
print(which(samp[x] == training$plot.id))
}
samp
length(samp)
length(unique(training$plot.id))
samp.rows <- numeric(length(samp))
for (x in 1:length(samp)){
print(which(samp[x] == training$plot.id))
}
samp.rows <- numeric(length(samp))
for (x in 1:length(samp)){
sample(which(samp[x] == training$plot.id))
}
samp.rows <- numeric(length(samp))
for (x in 1:length(samp)){
print(sample(which(samp[x] == training$plot.id)))
}
samp.rows <- numeric(length(samp))
for (x in 1:length(samp)){
print(sample(which(samp[x] == training$plot.id), 1))
}
samp.rows <- numeric(length(samp))
for (x in 1:length(samp)){
samp.rows[x] <- (sample(which(samp[x] == training$plot.id), 1))
}
samp.rows
unique(samp.rows)
length(samp.rows)
length(unique(samp.rows))
length(samp)
length(unique(samp))
#samp <- sample(nrow(training), train.size * nrow(training))
samp <- sample(unique(training$plot.id), train.size * length(unique(training$plot.id)), replace = FALSE)
length(samp)
# vector of rows to usee
samp.rows <- numeric(length(samp))
for (x in 1:length(samp)){
samp.rows[x] <- (sample(which(samp[x] == training$plot.id), 1))
}
samp.rows
length(samp.rows)
length(unique(samp.rows))
unique(training$plot.id)
length(samp)
length(unique(samp))
length(unique(training$plot.id))
# vector of rows to usee
samp.rows <- numeric(length(samp))
samp.rows <- numeric(length(samp))
for (x in 1:length(samp)){
samp.rows[x] <- (sample(which(samp[x] == training$plot.id), 1))
}
samp.rows
table(samp.rows)
unique(training$plot.id)
View(training)
