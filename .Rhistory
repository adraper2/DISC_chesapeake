for(x in 0 : (proc - 1)){
load(paste('OutCV',lake.name,x,'.rda',sep=''))
#paste(results, '\n')
posit <- count
for (y in 1 : length(results)){
if (length(results[[y]]) != 0){
cv.results[[count]] <- results[[y]]
}
}
rm(results) # to make sure we are grabbing the new results input
}
setwd('~/Documents/Junior_Year/DISC_REU/DISC_bayesian_model/')
save(cv.results,file=paste('cv_results_',lake.name,'.rda', sep=""))
# Aidan Draper
# June 29,2018
# this file takes the output .rda files from the HTCondor system process and produces one final .rda file called
# cv_results_{lake name}.rda
setwd('~/Documents/Junior_Year/DISC_REU/DISC_bayesian_model/BigWoodsLakes/outputBW')
proc <- 25 # number of processes
inp <- 3 # number of CVs run per process
lake.name <- "crystal"
cv.results = vector("list", ((proc) * inp))
count <- 1
for(x in 0 : (proc - 1)){
load(paste('OutCV',lake.name,x,'.rda',sep=''))
#paste(results, '\n')
posit <- count
for (y in 1 : length(results)){
if (length(results[[y]]) != 0){
cv.results[[count]] <- results[[y]]
count <- count + 1
}
}
rm(results) # to make sure we are grabbing the new results input
}
setwd('~/Documents/Junior_Year/DISC_REU/DISC_bayesian_model/')
save(cv.results,file=paste('cv_results_',lake.name,'.rda', sep=""))
rm(list=ls())
# import libraries
library(spBayes)
library(ggplot2)
library(coda)
library(gridExtra)
library(mgcv)
library(zoo)
library(Matrix)
library(stringr)
library(snow)
library(rlecuyer)
library(snowfall)
library(readxl)
#STEP 1: Setup and Data Manipulation
setwd("~/Documents/Junior_Year/DISC_REU/DISC_bayesian_model/BigWoodsLakes/")
# specify sheet number
curr.lake <- read_excel("bigwoods.xls", sheet = 5, col_names = TRUE)
char.dat <- data.frame(age=rep(NA,length(curr.lake$Date)))
# define variables from lake
char.dat$age <- with(curr.lake, round(Date) - 2018) # calculate YBP
char.dat$sed.rate <- with(curr.lake, Flux / Count) # NOTE: do not have age of sediment core so we left it fixed
char.dat$influx <- curr.lake$Flux
char.dat$count <- curr.lake$Count
qplot(age,count,data=char.dat)  + geom_smooth(method="loess", span=0.08) + theme_bw()
#STEP 2: Approximate background and foreground intensity (using cubic base spline) and set offset
char.dat$age.c = with(char.dat,age-min(age))
char.dat$age.s = with(char.dat,age.c/max(age.c))
n = nrow(char.dat)
n.knots = 31 # this variable will change for each model based on time interval
# note: smoothCon is part of the mgcv package for constructing the smooth terms in a GAM model
CRbasis = smoothCon(s(age.s,k=n.knots,bs="cr"),data=char.dat,knots=NULL,absorb.cons=TRUE,
scale.penalty=TRUE)
Sb = CRbasis[[1]]$S[[1]]
X = CRbasis[[1]]$X
knots = as.numeric(CRbasis[[1]]$xp)
S.scale = CRbasis[[1]]$S.scale
TT <- 1/char.dat$sed.rate # sets offset (inverse of sedimentation rate from STEP 1)
char.dat$sed.rate
curr.lake$Flux
curr.lake$Count
char.dat
if(is.nan(char.dat[1,2])) char.dat[1,2] <- 0
char.dat[1,2]
if(is.nan(char.dat[1,2])) char.dat[1,2] <- 1
char.dat[1,2]
qplot(age,count,data=char.dat)  + geom_smooth(method="loess", span=0.08) + theme_bw()
#STEP 2: Approximate background and foreground intensity (using cubic base spline) and set offset
char.dat$age.c = with(char.dat,age-min(age))
char.dat$age.s = with(char.dat,age.c/max(age.c))
n = nrow(char.dat)
n.knots = 31 # this variable will change for each model based on time interval
# note: smoothCon is part of the mgcv package for constructing the smooth terms in a GAM model
CRbasis = smoothCon(s(age.s,k=n.knots,bs="cr"),data=char.dat,knots=NULL,absorb.cons=TRUE,
scale.penalty=TRUE)
Sb = CRbasis[[1]]$S[[1]]
X = CRbasis[[1]]$X
knots = as.numeric(CRbasis[[1]]$xp)
S.scale = CRbasis[[1]]$S.scale
TT <- 1/char.dat$sed.rate # sets offset (inverse of sedimentation rate from STEP 1)
plot(char.dat$age, TT) # YOOOOO what the heck??? duuuuudee
char.dat$t.hold = rollapply(char.dat$count,50,function(x)quantile(x,0.9),fill="extend")
# Separate charcoal counts
y.back = y.fore = char.dat$count
y.back[char.dat$count>char.dat$t.hold] = NA # removes count value for background if the value is distributed in the 90% quantile
y.fore[char.dat$count<char.dat$t.hold] = NA # removes count value for background if the value is NOT distributed in the 90% quantile
#approximate the missing values (background = na.approx, foreground = randomly pulls value from binomial distribution)
y.back = round(na.approx(y.back))
y.fore[is.na(y.fore)] = rbinom(sum(is.na(y.fore)),1,0.1) # ask about why we add a bunch of zeros instead of NAs
# Plot background and foreground counts
plot(char.dat$age,y.back)
plot(char.dat$age,y.fore)
# Add separate counts to data.frame
char.dat$count.b = y.back
char.dat$count.f = y.fore
# Fit GAM Model to background (gam is part of mgcv package)
m1 = gam(y.back~X,family=poisson,offset=log(TT),paraPen=list(X=list(Sb,sp=0.001*S.scale)))
TT
TT[1]
is.infinite(TT)
if(is.infinite(TT)) TT[is.infinite(TT)] <- 0 # catch the count = 0 result being NaN for sed.rate
TT
is.infinite(TT)==TRUE]
TT[is.infinite(TT)==TRUE] <- 0
TT
TT[1] <- Inf
TT
TT[7] <- Inf
TT
if(is.infinite(TT)) TT[is.infinite(TT)==TRUE] <- 0 # catch the count = 0 result being NaN for sed.rate
TT
if(is.infinite(TT)) TT[is.infinite(TT)==TRUE] <- 0 # catch the Inf result incase 0 is in the denominator
TT
TT[7] <- Inf
TT
if(is.infinite(TT)) TT[is.infinite(TT)==TRUE] <- 0
TT
TT[is.infinite(TT)==TRUE] <- 0 # catch the Inf result incase 0 is in the denominator
TT
#STEP 2: Approximate background and foreground intensity (using cubic base spline) and set offset
char.dat$age.c = with(char.dat,age-min(age))
char.dat$age.s = with(char.dat,age.c/max(age.c))
n = nrow(char.dat)
n.knots = 31 # this variable will change for each model based on time interval
# note: smoothCon is part of the mgcv package for constructing the smooth terms in a GAM model
CRbasis = smoothCon(s(age.s,k=n.knots,bs="cr"),data=char.dat,knots=NULL,absorb.cons=TRUE,
scale.penalty=TRUE)
Sb = CRbasis[[1]]$S[[1]]
X = CRbasis[[1]]$X
knots = as.numeric(CRbasis[[1]]$xp)
S.scale = CRbasis[[1]]$S.scale
TT <- 1/char.dat$sed.rate # sets offset (inverse of sedimentation rate from STEP 1)
TT[is.infinite(TT)==TRUE] <- 0 # catch the Inf result incase 0 is in the denominator
plot(char.dat$age, TT) # YOOOOO what the heck??? duuuuudee
char.dat$t.hold = rollapply(char.dat$count,50,function(x)quantile(x,0.9),fill="extend")
# Separate charcoal counts
y.back = y.fore = char.dat$count
y.back[char.dat$count>char.dat$t.hold] = NA # removes count value for background if the value is distributed in the 90% quantile
y.fore[char.dat$count<char.dat$t.hold] = NA # removes count value for background if the value is NOT distributed in the 90% quantile
#approximate the missing values (background = na.approx, foreground = randomly pulls value from binomial distribution)
y.back = round(na.approx(y.back))
y.fore[is.na(y.fore)] = rbinom(sum(is.na(y.fore)),1,0.1) # ask about why we add a bunch of zeros instead of NAs
# Plot background and foreground counts
plot(char.dat$age,y.back)
plot(char.dat$age,y.fore)
# Add separate counts to data.frame
char.dat$count.b = y.back
char.dat$count.f = y.fore
# Fit GAM Model to background (gam is part of mgcv package)
m1 = gam(y.back~X,family=poisson,offset=log(TT),paraPen=list(X=list(Sb,sp=0.001*S.scale)))
args
args$X
log(TT)
rm(list=ls())
rm(list=ls())
library(ggplot2)
library(randomForest)
library(gridExtra)
setwd("~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/")
load(file='training_set.rda')
set.seed(2000)
curr.species = 'phau'
current <- training[,which(names(training)==curr.species)]
samp <- sample(nrow(training), .6 * nrow(training))
train <- training[samp,]
test <- training[-samp,]
View(train)
model = randomForest(phau ~ .,data = train[,-c(1:4,5:7,9:12,18)], keep.forest=TRUE)
model
plot(model)
varImpPlot(model)
pred <- predict(model, newdata = test)
table(pred, test$scam)
pred <- factor(pred, levels = c("none", "few", "few more", "little", "some", "most", "all"))
pred.graph <- ggplot() +
geom_rect(data=test, aes(xmin=easting, xmax=easting + 30, ymin=northing, ymax=northing + 30, fill = as.factor(unlist(pred))), color="black") +
labs(title=paste(curr.species, "Population Abundance Prediction w/ all vars"), x="Easting", y="Northing", fill="Cover") +
scale_x_continuous(limits = c(365430, 366280)) +
scale_y_continuous(limits = c(4303800, 4304470))
pred.graph
library(raster)
library(magrittr)
library(rgdal)
library(ggplot2)
setwd("~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/")
# create our crop region layer
e <- as(extent(365375, 366400, 4303600, 4304800), 'SpatialPolygons')
crs(e) <- "+proj=utm +zone=18"
# import bands, crop them to the SERC region and raster to a data frame
band2 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B2.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
band3 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B3.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
band4 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B4.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
band5 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B5.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
# NEED TO DOWNLOAD ARCMAP AND CREATE A .SHP FILE TO MASK THE PLOT TO (too much data currently)
# covariates for model and dataset construction
evi.value <- 2.5 * ((band5[1,3] - band4[1,3]) / (((band4[1,3] * 6) + band5[1,3]) - ((7.5 * band2[1,3]) + 1)))
ndvi.value <- ((band5[,3] - band4[,3]) / (band5[,3] + band4[,3]))
ndwi.value <- (band3[,3] - band5[,3]) / (band3[,3] + band5[,3])
savi.value <- (1.5 * ((band5[,3] - band4[,3]) / (band5[,3] + band4[,3] + 1.5)))
full.data <- data.frame(x = band2[,1],
y = band2[,2],
band2 = band2[,3],
band3 = band3[,3],
band4 = band4[,3],
band5 = band5[,3],
ndvi = ndvi.value,
evi = evi.value,
ndwi = ndwi.value,
savi = savi.value)
ggplot(data = full.data, aes(x=x, y=y)) + geom_point(aes(color = ndvi))
ggsave("plots/ndvi_test.png")
# compile the full dataframe to run
# Species Map Import
species <- read.csv("~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/DominantSpPerPlot.csv")
# remove plots with no location, if any
species <- species[!is.na(species$easting),]
species <- species[!is.na(species$northing),]
# convert UTM to lat, long
utm.coor.serc <- SpatialPoints(cbind(species$easting,species$northing),
proj4string=CRS("+proj=utm +zone=18"))
# Convert to lat/long
long.lat.coor.serc <- as.data.frame(spTransform(utm.coor.serc,CRS("+proj=longlat")))
species.map <- data.frame(species[2:9],
lat = long.lat.coor.serc$coords.x1,
lon = long.lat.coor.serc$coords.x2,
easting = utm.coor.serc$coords.x1,
northing = utm.coor.serc$coords.x2)
rm(species, long.lat.coor.serc, utm.coor.serc)
training <- data.frame(plot.id = numeric(1457), easting = numeric(1457), northing = numeric(1457), overlap = numeric(1457),
scam = numeric(1457), ivfr = numeric(1457), c4 = numeric(1457), phau = numeric(1457),
spcy = numeric(1457), tyla = numeric(1457), dead= numeric(1457), bare_water = numeric(1457),
band2 = numeric(1457), band3 = numeric(1457), band4 = numeric(1457), band5 = numeric(1457),
ndvi = numeric(1457), evi = numeric(1457), ndwi = numeric(1457), savi = numeric(1457))
count <- 0
for(i in 1:nrow(full.data)){
for (j in 1:nrow(species.map)){
if (species.map[j,11] - full.data[i,1] < 30 & species.map[j,11] - full.data[i,1] > -20 &
species.map[j,12] - full.data[i,2] < 30 & species.map[j,12] - full.data[i,2] > -20){
count = count + 1
training$plot.id[count] <- i
training[count,-c(1,4)] <- c(full.data[i,1:2],species.map[j,1:8], full.data[i,3:10])
if(species.map[j,11] - full.data[i,1] < 0){
# starting x point is outside landast
x.overlap <- (species.map[j,11] + 20) - full.data[i,1]
} else {
x.overlap <- (full.data[i,1] + 30) - species.map[j,11]
}
if(species.map[j,12] - full.data[i,2] < 0){
# starting y point is outside landast
y.overlap <- (species.map[j,12] + 20) - full.data[i,2]
} else {
y.overlap <- (full.data[i,2] + 30) - species.map[j,12]
}
#cat("Overlap Area: ", (x.overlap * y.overlap) / 900, "\n")
training$overlap[count] <- (x.overlap * y.overlap) / (30*30) # SERC plot overlap area / Landsat area
}
}
}
cols = c("none"="#ceb467", "few" = "#ace5b2", "few more" = "#7aef87", "little" = "#57d165", "some" = "#21a31d", "most" = "#197f24", "all" = "#115118")
pred.graph <- ggplot() +
geom_rect(data=test, aes(xmin=easting, xmax=easting + 30, ymin=northing, ymax=northing + 30, fill = as.factor(unlist(pred))), color="black") +
labs(title=paste(curr.species, "Population Abundance Prediction w/ all vars"), x="Easting", y="Northing", fill="Cover") +
scale_x_continuous(limits = c(365430, 366280)) +
scale_y_continuous(limits = c(4303800, 4304470))
pred.graph
pred.graph <- ggplot() +
geom_rect(data=test, aes(xmin=easting, xmax=easting + 30, ymin=northing, ymax=northing + 30, fill = as.factor(unlist(pred))), color="black") +
labs(title=paste(curr.species, "Population Abundance Prediction w/ all vars"), x="Easting", y="Northing", fill="Cover") +
scale_x_continuous(limits = c(365430, 366280)) +
scale_y_continuous(limits = c(4303800, 4304470)) +
scale_fill_manual(values = cols)
pred.graph
pred.graph <- ggplot() +
geom_rect(data=test, aes(xmin=easting, xmax=easting + 30, ymin=northing, ymax=northing + 30, fill = as.factor(unlist(pred))), color="black") +
labs(title=paste(curr.species, "Population Abundance Prediction without SERC"), x="Easting", y="Northing", fill="Cover") +
scale_x_continuous(limits = c(365430, 366280)) +
scale_y_continuous(limits = c(4303800, 4304470)) +
scale_fill_manual(values = cols)
pred.graph
pred.graph <- ggplot() +
geom_rect(data=test, aes(xmin=easting, xmax=easting + 30, ymin=northing, ymax=northing + 30, fill = as.factor(unlist(pred))), color="black") +
labs(title=paste(curr.species, "Pop. Abundance Prediction (no SERC)"), x="Easting", y="Northing", fill="Cover") +
scale_x_continuous(limits = c(365430, 366280)) +
scale_y_continuous(limits = c(4303800, 4304470)) +
scale_fill_manual(values = cols)
pred.graph
ggsave(paste("plots/prediction_visual_",curr.species,"2.png", sep=""))
getwd()
species.map$phau <- factor(species.map$phau, levels = c("none", "few", "few more", "little", "some", "most", "all"))
cols = c("none"="#ceb467", "few" = "#ace5b2", "few more" = "#7aef87", "little" = "#57d165", "some" = "#21a31d", "most" = "#197f24", "all" = "#115118")
serc.plots <- ggplot() +
geom_rect(data=species.map, aes(xmin=easting, xmax=easting + 20, ymin=northing, ymax=northing + 20, fill = as.factor(unlist(species.map[4]))), color=NA) +
labs(title=paste("phau Population Abundance in SERC Plots"), x="Easting", y="Northing", fill = "Cover") +
geom_rect(data=training, aes(xmin=easting, xmax=easting + 30, ymin=northing, ymax=northing + 30), color="black", fill = NA) +
scale_x_continuous(limits = c(365430, 366280)) +
scale_y_continuous(limits = c(4303800, 4304470)) +
scale_fill_manual(values = cols)
serc.plots
setwd("~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/")
# create our crop region layer
e <- as(extent(365375, 366400, 4303600, 4304800), 'SpatialPolygons')
crs(e) <- "+proj=utm +zone=18"
# import bands, crop them to the SERC region and raster to a data frame
band2 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B2.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
band3 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B3.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
band4 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B4.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
band5 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B5.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
# NEED TO DOWNLOAD ARCMAP AND CREATE A .SHP FILE TO MASK THE PLOT TO (too much data currently)
# covariates for model and dataset construction
evi.value <- 2.5 * ((band5[1,3] - band4[1,3]) / (((band4[1,3] * 6) + band5[1,3]) - ((7.5 * band2[1,3]) + 1)))
ndvi.value <- ((band5[,3] - band4[,3]) / (band5[,3] + band4[,3]))
ndwi.value <- (band3[,3] - band5[,3]) / (band3[,3] + band5[,3])
savi.value <- (1.5 * ((band5[,3] - band4[,3]) / (band5[,3] + band4[,3] + 1.5)))
full.data <- data.frame(x = band2[,1],
y = band2[,2],
band2 = band2[,3],
band3 = band3[,3],
band4 = band4[,3],
band5 = band5[,3],
ndvi = ndvi.value,
evi = evi.value,
ndwi = ndwi.value,
savi = savi.value)
ggplot(data = full.data, aes(x=x, y=y)) + geom_point(aes(color = ndvi))
ggsave("plots/ndvi_test.png")
# compile the full dataframe to run
# Species Map Import
species <- read.csv("~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/DominantSpPerPlot.csv")
# remove plots with no location, if any
species <- species[!is.na(species$easting),]
species <- species[!is.na(species$northing),]
# convert UTM to lat, long
utm.coor.serc <- SpatialPoints(cbind(species$easting,species$northing),
proj4string=CRS("+proj=utm +zone=18"))
# Convert to lat/long
long.lat.coor.serc <- as.data.frame(spTransform(utm.coor.serc,CRS("+proj=longlat")))
species.map <- data.frame(species[2:9],
lat = long.lat.coor.serc$coords.x1,
lon = long.lat.coor.serc$coords.x2,
easting = utm.coor.serc$coords.x1,
northing = utm.coor.serc$coords.x2)
rm(species, long.lat.coor.serc, utm.coor.serc)
training <- data.frame(plot.id = numeric(1457), easting = numeric(1457), northing = numeric(1457), overlap = numeric(1457),
scam = numeric(1457), ivfr = numeric(1457), c4 = numeric(1457), phau = numeric(1457),
spcy = numeric(1457), tyla = numeric(1457), dead= numeric(1457), bare_water = numeric(1457),
band2 = numeric(1457), band3 = numeric(1457), band4 = numeric(1457), band5 = numeric(1457),
ndvi = numeric(1457), evi = numeric(1457), ndwi = numeric(1457), savi = numeric(1457))
count <- 0
for(i in 1:nrow(full.data)){
for (j in 1:nrow(species.map)){
if (species.map[j,11] - full.data[i,1] < 30 & species.map[j,11] - full.data[i,1] > -20 &
species.map[j,12] - full.data[i,2] < 30 & species.map[j,12] - full.data[i,2] > -20){
count = count + 1
training$plot.id[count] <- i
training[count,-c(1,4)] <- c(full.data[i,1:2],species.map[j,1:8], full.data[i,3:10])
if(species.map[j,11] - full.data[i,1] < 0){
# starting x point is outside landast
x.overlap <- (species.map[j,11] + 20) - full.data[i,1]
} else {
x.overlap <- (full.data[i,1] + 30) - species.map[j,11]
}
if(species.map[j,12] - full.data[i,2] < 0){
# starting y point is outside landast
y.overlap <- (species.map[j,12] + 20) - full.data[i,2]
} else {
y.overlap <- (full.data[i,2] + 30) - species.map[j,12]
}
#cat("Overlap Area: ", (x.overlap * y.overlap) / 900, "\n")
training$overlap[count] <- (x.overlap * y.overlap) / (30*30) # SERC plot overlap area / Landsat area
}
}
}
library(raster)
library(magrittr)
library(rgdal)
library(ggplot2)
setwd("~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/")
# create our crop region layer
e <- as(extent(365375, 366400, 4303600, 4304800), 'SpatialPolygons')
crs(e) <- "+proj=utm +zone=18"
# import bands, crop them to the SERC region and raster to a data frame
band2 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B2.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
band3 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B3.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
band4 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B4.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
band5 <- "Landsat8/LC08_L1TP_015033_20160718_20170222_01_T1/LC08_L1TP_015033_20160718_20170222_01_T1_B5.TIF" %>% raster() %>% crop(y = e) %>% rasterToPoints()
# NEED TO DOWNLOAD ARCMAP AND CREATE A .SHP FILE TO MASK THE PLOT TO (too much data currently)
# covariates for model and dataset construction
evi.value <- 2.5 * ((band5[1,3] - band4[1,3]) / (((band4[1,3] * 6) + band5[1,3]) - ((7.5 * band2[1,3]) + 1)))
ndvi.value <- ((band5[,3] - band4[,3]) / (band5[,3] + band4[,3]))
ndwi.value <- (band3[,3] - band5[,3]) / (band3[,3] + band5[,3])
savi.value <- (1.5 * ((band5[,3] - band4[,3]) / (band5[,3] + band4[,3] + 1.5)))
full.data <- data.frame(x = band2[,1],
y = band2[,2],
band2 = band2[,3],
band3 = band3[,3],
band4 = band4[,3],
band5 = band5[,3],
ndvi = ndvi.value,
evi = evi.value,
ndwi = ndwi.value,
savi = savi.value)
ggplot(data = full.data, aes(x=x, y=y)) + geom_point(aes(color = ndvi))
# ggsave("plots/ndvi_test.png")
# compile the full dataframe to run
# Species Map Import
species <- read.csv("~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/DominantSpPerPlot.csv")
# remove plots with no location, if any
species <- species[!is.na(species$easting),]
species <- species[!is.na(species$northing),]
# convert UTM to lat, long
utm.coor.serc <- SpatialPoints(cbind(species$easting,species$northing),
proj4string=CRS("+proj=utm +zone=18"))
# Convert to lat/long
long.lat.coor.serc <- as.data.frame(spTransform(utm.coor.serc,CRS("+proj=longlat")))
species.map <- data.frame(species[2:9],
lat = long.lat.coor.serc$coords.x1,
lon = long.lat.coor.serc$coords.x2,
easting = utm.coor.serc$coords.x1,
northing = utm.coor.serc$coords.x2)
rm(species, long.lat.coor.serc, utm.coor.serc)
training <- data.frame(plot.id = numeric(1457), easting = numeric(1457), northing = numeric(1457), overlap = numeric(1457),
scam = numeric(1457), ivfr = numeric(1457), c4 = numeric(1457), phau = numeric(1457),
spcy = numeric(1457), tyla = numeric(1457), dead= numeric(1457), bare_water = numeric(1457),
band2 = numeric(1457), band3 = numeric(1457), band4 = numeric(1457), band5 = numeric(1457),
ndvi = numeric(1457), evi = numeric(1457), ndwi = numeric(1457), savi = numeric(1457))
count <- 0
for(i in 1:nrow(full.data)){
for (j in 1:nrow(species.map)){
if (species.map[j,11] - full.data[i,1] < 30 & species.map[j,11] - full.data[i,1] > -20 &
species.map[j,12] - full.data[i,2] < 30 & species.map[j,12] - full.data[i,2] > -20){
count = count + 1
training$plot.id[count] <- i
training[count,-c(1,4)] <- c(full.data[i,1:2],species.map[j,1:8], full.data[i,3:10])
if(species.map[j,11] - full.data[i,1] < 0){
# starting x point is outside landast
x.overlap <- (species.map[j,11] + 20) - full.data[i,1]
} else {
x.overlap <- (full.data[i,1] + 30) - species.map[j,11]
}
if(species.map[j,12] - full.data[i,2] < 0){
# starting y point is outside landast
y.overlap <- (species.map[j,12] + 20) - full.data[i,2]
} else {
y.overlap <- (full.data[i,2] + 30) - species.map[j,12]
}
#cat("Overlap Area: ", (x.overlap * y.overlap) / 900, "\n")
training$overlap[count] <- (x.overlap * y.overlap) / (30*30) # SERC plot overlap area / Landsat area
}
}
}
paste("Yes count:", count)
nrow(training)
# reassign ordinal values words
for (z in 5:12){
training[which(is.na(training[,z])),z] <- "none"
training[which(training[,z] == 0),z] <- "few"
training[which(training[,z] == 1),z] <- "few more"
training[which(training[,z] == 2),z] <- "little"
training[which(training[,z] == 3),z] <- "some"
training[which(training[,z] == 4),z] <- "most"
training[which(training[,z] == 5),z] <- "all"
training[,z] <- as.factor(training[,z])
}
# save(training, file = '~/Documents/Junior_Year/DISC_REU/DISC_chesapeake/training_set.rda')
#graph current species under landsat plots
ggplot() +
geom_rect(data=species.map, aes(xmin=(easting - min(training$easting))/30, xmax=(easting - min(training$easting) + 20)/30, ymin=(northing -min(training$northing))/30, ymax=(northing -min(training$northing) + 20)/30, fill = as.factor(unlist(species.map[2]))), color=NA) +
labs(title=paste("Population Abundance"), x="X (30m increment)", y="Y (30m increment)", fill = "Cover") +
geom_rect(data=training, aes(xmin=(easting - min(training$easting))/30, xmax=(easting - min(training$easting) + 30)/30, ymin=(northing-min(training$northing))/30, ymax=(northing + 30 - min(training$northing))/30), color="black", fill = NA)
# edit scale for validation
species.map[which(is.na(species.map[,4])),4] <- "none"
species.map[which(species.map[,4] == 0),4] <- "few"
species.map[which(species.map[,4] == 1),4] <- "few more"
species.map[which(species.map[,4] == 2),4] <- "little"
species.map[which(species.map[,4] == 3),4] <- "some"
species.map[which(species.map[,4] == 4),4] <- "most"
species.map[which(species.map[,4] == 5),4] <- "all"
species.map[,4] <- as.factor(species.map[,4])
# for validation after model run
species.map$phau <- factor(species.map$phau, levels = c("none", "few", "few more", "little", "some", "most", "all"))
cols = c("none"="#ceb467", "few" = "#ace5b2", "few more" = "#7aef87", "little" = "#57d165", "some" = "#21a31d", "most" = "#197f24", "all" = "#115118")
serc.plots <- ggplot() +
geom_rect(data=species.map, aes(xmin=easting, xmax=easting + 20, ymin=northing, ymax=northing + 20, fill = as.factor(unlist(species.map[4]))), color=NA) +
labs(title=paste("phau Population Abundance in SERC Plots"), x="Easting", y="Northing", fill = "Cover") +
geom_rect(data=training, aes(xmin=easting, xmax=easting + 30, ymin=northing, ymax=northing + 30), color="black", fill = NA) +
scale_x_continuous(limits = c(365430, 366280)) +
scale_y_continuous(limits = c(4303800, 4304470)) +
scale_fill_manual(values = cols)
serc.plots
# need to run training.R concurrently
grid.arrange(serc.plots, pred.graph, ncol=2)
ggsave(paste("plots/plot_comparison_",curr.species,"2.png", sep=""), arrangeGrob(serc.plots, pred2.graph, ncol=2), width = 11)
# need to run training.R concurrently
grid.arrange(serc.plots, pred.graph, ncol=2)
ggsave(paste("plots/plot_comparison_",curr.species,"2.png", sep=""), arrangeGrob(serc.plots, pred.graph, ncol=2), width = 11)
